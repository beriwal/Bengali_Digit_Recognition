{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "TLCd3o98GdiB"
   },
   "source": [
    "### **Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c59Q8-WyQB0q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import io\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "BZg3JF_8GpMy"
   },
   "source": [
    "### **Set the random seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YI0uy-RLQZbY"
   },
   "outputs": [],
   "source": [
    "seed = 3\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "tCXc5TtQG-Ti"
   },
   "source": [
    "### **Load and preprocess data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "#unzip BDRW_train_1.zip\n",
    "z = zipfile.ZipFile('../input/bdrw/BDRW_train/BDRW_train_1.zip', \"r\")\n",
    "for name in z.namelist():\n",
    "    z.extract(name)\n",
    "    \n",
    "#unzip BDRW_train_2.zip    \n",
    "z = zipfile.ZipFile('../input/bdrw/BDRW_train/BDRW_train_2.zip', \"r\")\n",
    "for name in z.namelist():\n",
    "    z.extract(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the excel file-labels.xls containing the image labels\n",
    "labels = pd.read_excel('BDRW_train_2/labels.xls')\n",
    "labels.columns = ['digit', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>digit</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>digit_1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>digit_2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>digit_3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>digit_4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>digit_5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     digit  label\n",
       "0  digit_1      4\n",
       "1  digit_2      2\n",
       "2  digit_3      3\n",
       "3  digit_4      1\n",
       "4  digit_5      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the labels dataframe\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "xPDdmuMjINK7"
   },
   "source": [
    "### **Check the class distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XVXPiTvDeMdE",
    "outputId": "6a54f3b0-31ae-45dd-c69c-60788e2274c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9e7a24f410>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot a histogram with x-axis : class label, y-axis : percentage of data in that class\n",
    "labels['label'].hist(density = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "-su8p0eGHPAU"
   },
   "source": [
    "### **Read the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in BDRW_train_1:  984\n",
      "Number of images in BDRW_train_2:  410\n",
      "First 5 images in BDRW_train_1: ['digit_433', 'digit_695', 'digit_956', 'digit_897', 'digit_26']\n",
      "First 5 images in BDRW_train_2: ['digit_1377', 'digit_1226', 'digit_1188', 'digit_1373', 'digit_1199']\n"
     ]
    }
   ],
   "source": [
    "bdrw_train_1 = [f[13:-4] for f in glob.glob(\"BDRW_train_1/*\")] #list of image names in BDRW_train_1 folder\n",
    "bdrw_train_2 = [f[13:-4] for f in glob.glob(\"BDRW_train_2/*\")] #list of image names in BDRW_train_2 folder\n",
    "\n",
    "print('Number of images in BDRW_train_1: ', len(bdrw_train_1))\n",
    "print('Number of images in BDRW_train_2: ', len(bdrw_train_2))\n",
    "\n",
    "print('First 5 images in BDRW_train_1:', bdrw_train_1[:5])\n",
    "print('First 5 images in BDRW_train_2:', bdrw_train_2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VHQxlyjDZkxK",
    "outputId": "db1d09d2-a2f6-42ec-de36-8e8002b3784c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (1392, 32, 32) \t Shape of y:  (1392,)\n"
     ]
    }
   ],
   "source": [
    "size = 32 #size of the resized image\n",
    "X = []\n",
    "\n",
    "for i,row in labels.iterrows(): #loop across the rows of the 'labels' dataframe\n",
    "    \n",
    "    #read the image in the 'digit' column of 'labels' dataframe\n",
    "    if(row['digit'] in bdrw_train_1): #if the image is in BDRW_train_1 folder\n",
    "        image = cv2.imread('BDRW_train_1/' + row['digit'] + \".jpg\", 0)  \n",
    "    else:  #if the image is in BDRW_train_2 folder\n",
    "        image = cv2.imread('BDRW_train_2/' + row['digit'] + \".jpg\", 0)\n",
    "        \n",
    "    image = cv2.resize(image, dsize = (size,size)) #resize the image\n",
    "    X.append(image) #append the image to the list\n",
    "\n",
    "X = np.array(X) #convert the image into numpy array\n",
    "X = X/float(255.0) #normalize the values\n",
    "y = labels['label'].values #get the labels\n",
    "\n",
    "print(\"Shape of X: \", X.shape, \"\\t Shape of y: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "C1W45NCiKZ3s"
   },
   "source": [
    "### **Train-Test-Validation Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PwS8bCjLwIRt",
    "outputId": "0b96c324-fff0-48e6-92b0-391c7c28a364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data: \t\t ((974, 32, 32), (974,))\n",
      "Shape of validation data: \t ((209, 32, 32), (209,))\n",
      "Shape of test data: \t\t ((209, 32, 32), (209,))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.70, random_state = 25, stratify = y) #put 70% data in train\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.50, random_state = 25, stratify = y_test) #put 15% data in test and validation each\n",
    "\n",
    "print(\"Shape of train data: \\t\\t\", (X_train.shape, y_train.shape))\n",
    "print(\"Shape of validation data: \\t\", (X_val.shape, y_val.shape))\n",
    "print(\"Shape of test data: \\t\\t\", (X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "nE5KwDPpKvFn"
   },
   "source": [
    "### **Convert the data into usable torch format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dwuUh3d4wLsO",
    "outputId": "acb1d082-660c-47e0-dfc5-df3d103d121e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data, \t X :  torch.Size([974, 1, 32, 32]) \t and y:  torch.Size([974])\n",
      "Shape of val. data, \t X :  torch.Size([209, 1, 32, 32]) \t and y:  torch.Size([209])\n",
      "Shape of test data, \t X :  torch.Size([209, 1, 32, 32]) \t and y:  torch.Size([209])\n"
     ]
    }
   ],
   "source": [
    "# converting training images into torch format\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], X_train.shape[2])\n",
    "X_train  = torch.from_numpy(X_train)\n",
    "\n",
    "# converting the training labels into torch format\n",
    "y_train = y_train.astype(int);\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_train = y_train.squeeze()\n",
    "\n",
    "# shape of training data\n",
    "print(\"Shape of train data, \\t X : \", X_train.shape,\"\\t and y: \", y_train.shape)\n",
    "\n",
    "# converting validation images into torch format\n",
    "X_val = X_val.reshape(X_val.shape[0], 1, X_val.shape[1], X_val.shape[2])\n",
    "X_val  = torch.from_numpy(X_val)\n",
    "\n",
    "# converting the validation labels into torch format\n",
    "y_val = y_val.astype(int);\n",
    "y_val = torch.from_numpy(y_val)\n",
    "y_val = y_val.squeeze()\n",
    "\n",
    "# shape of validation data\n",
    "print(\"Shape of val. data, \\t X : \", X_val.shape,\"\\t and y: \", y_val.shape) \n",
    "\n",
    "# converting test images into torch format\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1], X_test.shape[2])\n",
    "X_test  = torch.from_numpy(X_test)\n",
    "\n",
    "# converting the test labels into torch format\n",
    "y_test = y_test.astype(int);\n",
    "y_test = torch.from_numpy(y_test)\n",
    "y_test = y_test.squeeze()\n",
    "\n",
    "# shape of test data\n",
    "print(\"Shape of test data, \\t X : \", X_test.shape,\"\\t and y: \", y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "_fSNOc4hLYAI"
   },
   "source": [
    "### **Function to create minibatches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "piklJcVkwQkA"
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 32, seed = 3):\n",
    "    \n",
    "    np.random.seed(seed)            \n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation,:,:,:]\n",
    "    shuffled_Y = Y[permutation].reshape((m,1))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Excluding the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of complete mini batches of size mini_batch_size\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[mini_batch_size*k : mini_batch_size*(k+1), :, :, :]\n",
    "        mini_batch_Y = shuffled_Y[mini_batch_size*k : mini_batch_size*(k+1), :]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[mini_batch_size*num_complete_minibatches : , :, :, :]\n",
    "        mini_batch_Y = shuffled_Y[mini_batch_size*num_complete_minibatches : , :]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "8gwF0PMjL_-A"
   },
   "source": [
    "### **Define the Network Architechture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gtmWxSUlwUB4"
   },
   "outputs": [],
   "source": [
    "#An architechture inspired from the famous LeNet5 architechture\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size = 5, stride = 1, padding = 0) #input size:1*32*32 , output size: 6*28*28 \n",
    "        self.max_pool_1 = nn.MaxPool2d(kernel_size=2) #input size:6*28*28 , output size: 6*14*14 \n",
    "        self.batch_norm_1 = nn.BatchNorm2d(6) #normalizes the input to the next conv2d layer\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size = 5, stride = 1, padding = 0) #input size:6*14*14 , output size: 16*10*10 \n",
    "        self.max_pool_2 = nn.MaxPool2d(kernel_size=2) #input size:16*10*10 , output size:16*5*5 \n",
    "        self.batch_norm_2 = nn.BatchNorm2d(16) #normalizes the input to the next fully connected layer\n",
    "        self.fc1 = nn.Linear(16*5*5, 120) #input size:16*5*5 , output size: 120\n",
    "        self.dropout_1 = nn.Dropout(p = 0.5) #dropout for regularization (to prevent overfitting on the train set)\n",
    "        self.fc2 = nn.Linear(120, 84) #input size:120 , output size: 84\n",
    "        self.dropout_2 = nn.Dropout(p = 0.5) #dropout for regularization (to prevent overfitting on the train set)\n",
    "        self.fc3 = nn.Linear(84, 10) #input size:84 , output size: 10 (no. of classes for our problem)\n",
    "\n",
    "#define the data flow\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.max_pool_1(x)\n",
    "        x = self.batch_norm_1(x)\n",
    "        x = x = F.relu(self.conv2(x))\n",
    "        x = self.max_pool_2(x)\n",
    "        x = self.batch_norm_2(x)\n",
    "        x = x.view(-1, 16*5*5) #reshape for input to the fully connected layer 1 (fc1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout_1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "HLs_K9GBQjwB"
   },
   "source": [
    "### **Define model, optimizer, loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0KJyoa74wYXT",
    "outputId": "d1fc29fa-0b60-4142-8e26-6f8121179ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (max_pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (batch_norm_1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (max_pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (batch_norm_2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (dropout_1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (dropout_2): Dropout(p=0.5, inplace=False)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = Net()\n",
    "model = model.float()\n",
    "\n",
    "# defining the optimizer\n",
    "learning_rate = 0.0004\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate) #Adam optimizer\n",
    "\n",
    "# defining the loss function\n",
    "values, counts = np.unique(y_train.float(), return_counts = True)\n",
    "weights = sum(counts)/counts\n",
    "weights = torch.tensor(weights, dtype = torch.float)\n",
    "criterion = nn.CrossEntropyLoss(weight = weights) #weights used to deal with the Class Imbalance problem\n",
    "\n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "d90Xkpw6Q_14"
   },
   "source": [
    "### **Training function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "r8P-pVzswbl_"
   },
   "outputs": [],
   "source": [
    "def train(epoch, X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    # converting the data into GPU format\n",
    "    if torch.cuda.is_available():\n",
    "        X_train = X_train.cuda()\n",
    "        y_train = y_train.cuda()\n",
    "        X_val = X_val.cuda()\n",
    "        y_val = y_val.cuda()\n",
    "\n",
    "    # clearing the Gradients of the model parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # prediction for training and validation set\n",
    "    output_train = model(X_train.float())\n",
    "    output_val = model(X_val.float())\n",
    "    \n",
    "    # computing the training and validation loss\n",
    "    loss_train = criterion(output_train, y_train.long())\n",
    "    loss_val = criterion(output_val, y_val.long())\n",
    "        \n",
    "    # computing the predictions for training and validation set\n",
    "    preds_train = torch.argmax(output_train,dim=1)\n",
    "    preds_val = torch.argmax(output_val,dim=1)\n",
    "\n",
    "    # computing the updated weights of all the model parameters\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return((loss_val, preds_val), (loss_train, preds_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "l1eGM3HPR_rm"
   },
   "source": [
    "### **Training the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "I_WBXxaJwhLA",
    "outputId": "6599e7bf-6ae4-4a3b-e693-2cffb16cdc17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 : Validation loss: 2.1288 | Validation Accuracy: 30.4730\n",
      "Epoch 4/50 : Validation loss: 1.4082 | Validation Accuracy: 55.0553\n",
      "Epoch 6/50 : Validation loss: 0.9292 | Validation Accuracy: 68.7505\n",
      "Epoch 8/50 : Validation loss: 0.6895 | Validation Accuracy: 76.7746\n",
      "Epoch 10/50 : Validation loss: 0.5374 | Validation Accuracy: 82.0927\n",
      "Epoch 12/50 : Validation loss: 0.4732 | Validation Accuracy: 84.0850\n",
      "Epoch 14/50 : Validation loss: 0.4149 | Validation Accuracy: 85.8891\n",
      "Epoch 16/50 : Validation loss: 0.3836 | Validation Accuracy: 87.1676\n",
      "Epoch 18/50 : Validation loss: 0.3620 | Validation Accuracy: 88.2657\n",
      "Epoch 20/50 : Validation loss: 0.3292 | Validation Accuracy: 88.9168\n",
      "Epoch 22/50 : Validation loss: 0.3095 | Validation Accuracy: 89.4972\n",
      "Epoch 24/50 : Validation loss: 0.2920 | Validation Accuracy: 89.9992\n",
      "Epoch 26/50 : Validation loss: 0.2749 | Validation Accuracy: 90.5326\n",
      "Epoch 28/50 : Validation loss: 0.2763 | Validation Accuracy: 90.5953\n",
      "Epoch 30/50 : Validation loss: 0.2645 | Validation Accuracy: 91.4268\n",
      "Epoch 32/50 : Validation loss: 0.2706 | Validation Accuracy: 91.6386\n",
      "Epoch 34/50 : Validation loss: 0.2670 | Validation Accuracy: 91.5601\n",
      "Epoch 36/50 : Validation loss: 0.2955 | Validation Accuracy: 91.1287\n",
      "Epoch 38/50 : Validation loss: 0.2594 | Validation Accuracy: 91.8111\n",
      "Epoch 40/50 : Validation loss: 0.2542 | Validation Accuracy: 91.8739\n",
      "Epoch 42/50 : Validation loss: 0.2867 | Validation Accuracy: 91.3405\n",
      "Epoch 44/50 : Validation loss: 0.2776 | Validation Accuracy: 91.5601\n",
      "Epoch 46/50 : Validation loss: 0.3162 | Validation Accuracy: 91.0895\n",
      "Epoch 48/50 : Validation loss: 0.2867 | Validation Accuracy: 91.2464\n",
      "Epoch 50/50 : Validation loss: 0.2893 | Validation Accuracy: 91.4032\n"
     ]
    }
   ],
   "source": [
    "seed = 3 #random seed\n",
    "n_epochs = 50 #number of epochs\n",
    "mini_batch_size = 16 #size of the mini batch\n",
    "m = X_train.shape[0] #no of training examples\n",
    "n_batches = np.ceil(y_train.shape[0]/mini_batch_size) #no of batches\n",
    "\n",
    "# empty lists to store training losses, accuracy\n",
    "train_losses = []\n",
    "train_accuracy = []\n",
    "\n",
    "# empty lists to store validation losses, accuracy\n",
    "val_losses = []\n",
    "val_accuracy = []\n",
    "\n",
    "# training the model\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    val_running_loss = 0\n",
    "    val_running_corr = 0\n",
    "    train_running_loss = 0\n",
    "    train_running_corr = 0\n",
    "    seed += 1 #change the seed to reshuffle the dataset differently after each epoch \n",
    "    minibatches = random_mini_batches(X_train, y_train, mini_batch_size, seed) #get the minibacthes\n",
    "    i = 0\n",
    "    \n",
    "    for minibatch in minibatches:\n",
    "        \n",
    "        (minibatch_X, minibatch_Y) = minibatch\n",
    "        size = minibatch_Y.shape[0] #get the size of minibatch_Y\n",
    "        minibatch_Y = torch.reshape(minibatch_Y, (size,)) #reshape appropriately \n",
    "        (loss_val, preds_val), (loss_train, preds_train) = train(epoch, minibatch_X, minibatch_Y, X_val, y_val) #get the losses and predictions after training\n",
    "        \n",
    "        val_running_loss += loss_val \n",
    "        val_running_corr += torch.sum(preds_val == y_val.long())\n",
    "        train_running_loss += loss_train \n",
    "        train_running_corr += torch.sum(preds_train == minibatch_Y.long())\n",
    "        i = i+1\n",
    "        \n",
    "    val_epoch_loss = val_running_loss.item()/i\n",
    "    val_epoch_acc = val_running_corr.item()/(X_val.shape[0] * i)\n",
    "    if((epoch+1)%2 == 0):\n",
    "        print('Epoch {:.0f}/{:.0f} : Validation loss: {:.4f} | Validation Accuracy: {:.4f}'.format(epoch+1,n_epochs,val_epoch_loss,val_epoch_acc*100))\n",
    "    \n",
    "    train_epoch_loss = train_running_loss.item()/i\n",
    "    train_epoch_acc = train_running_corr.item()/X_train.shape[0]\n",
    "    \n",
    "    #append the losses and accuracies to the lists\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    train_accuracy.append(train_epoch_acc)\n",
    "    val_accuracy.append(val_epoch_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "iJ_f6HppUOxA"
   },
   "source": [
    "### **Plot the training and validation loss curves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "sGmpD0DH-shK",
    "outputId": "a45af96b-08a5-407b-e4fa-539135fa7488"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "JYxK-KvzTqJD"
   },
   "source": [
    "### **Check the model accuracy on the unseen test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fFHoWqciyW5g",
    "outputId": "2f2d03bc-1040-4ef4-8255-2fc317a11bd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy is: 89.4737\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    X_test = X_test.cuda()\n",
    "    y_test = y_test.cuda()\n",
    "output_test = model(X_test.float())\n",
    "output_test = torch.exp(output_test)\n",
    "preds_test =  torch.argmax(output_test,dim=1)\n",
    "test_acc = 100*torch.sum(preds_test == y_test.long()).item()/len(y_test)\n",
    "print('Testing accuracy is: %0.4f'%test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "### **Model complexity calculations**"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "1. **Conv2d layer 1:** #input size: 1x32x32 , output size: 6x28x28 <br>\n",
    "Params = (cwh + 1)k = ((1 * 5 * 5) + 1) * 6 = 156 <br>\n",
    "Flops = (cwh + 1)k * Ow * Oh = ((1 * 5 * 5) + 1) * 6 * 28 * 28 = 122304 <br>\n",
    "\n",
    "2. **ReLU:** #input size: 6x28x28  , output size: 6x28x28 <br>\n",
    "Params = 0 <br>\n",
    "Flops = 2cMN = 2 * 6 * 28 * 28 = 9408 <br>\n",
    "\n",
    "3. **Max pool layer 1:** #input size: 6x28x28  , output size: 6x14x14 <br>\n",
    "Params = 0 <br>\n",
    "Flops = c*(wh - 1) * Ow * Oh = 6 * ((2 * 2) - 1) * 14 * 14 = 3528 <br>\n",
    "\n",
    "4. **Conv2d layer 2:** #input size: 6x14x14  , output size: 16x10x10  <br>\n",
    "Params = (cwh + 1)k = ((6 * 5 * 5) + 1) * 16 = 2416 <br>\n",
    "Flops = (cwh + 1)k * Ow * Oh = ((6 * 5 * 5) + 1) * 16 * 10 * 10 = 241600 <br>\n",
    "\n",
    "5. **ReLU:** #input size:  16x10x10   , output size:  16x10x10   <br>\n",
    "Params = 0 <br>\n",
    "Flops = 2cMN = 2 * 16 * 10 * 10 = 3200 <br>\n",
    "\n",
    "6. **Max pool layer 2:** #input size: 16x10x10  , output size: 16x5x5  <br>\n",
    "Params = 0 <br>\n",
    "Flops = c*(wh - 1) * Ow * Oh = 16*((2 * 2) - 1) * 5 * 5 = 1200 <br>\n",
    "\n",
    "7. **Fully connected layer 1:** #input size: 16x5x5, output size: 120 <br>\n",
    "Params = (n + 1)k = (16 * 5 * 5 + 1) * 120 = 48120 <br>\n",
    "Flops = (n + 1)k = (16 * 5 * 5 + 1) * 120 = 48120 <br>\n",
    "\n",
    "8. **ReLU:** #input size: 120, output size: 120 <br>\n",
    "Params = 0 <br>\n",
    "Flops = 2n = 2 * 120 = 240 <br>\n",
    "\n",
    "9. **Fully connected layer 2:** #input size: 120, output size: 84 <br>\n",
    "Params = (n + 1)k = (120 + 1) * 84 = 10164 <br>\n",
    "Flops = (n + 1)k = (120 + 1) * 84 = 10164 <br>\n",
    "\n",
    "10. **ReLU:** #input size: 84, output size: 84 <br>\n",
    "Params = 0 <br>\n",
    "Flops = 2n = 2 * 84 = 168 <br>\n",
    "\n",
    "11. **Fully connected layer 3:** #input size: 84, output size: 10 <br>\n",
    "Params = (n + 1)k = (84 + 1) * 10 = 850 <br>\n",
    "Flops = (n + 1)k = (84 + 1) * 10 = 850 <br>\n",
    "\n",
    "**Total Params = 61,706 <br>\n",
    "Total FLOPS = 440,782 <br>**\n",
    "\n",
    "Note: Assuming that #params and #flops for dropout and batch normalization layers ~ 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
